\documentclass{beamer}
\usetheme{boadilla}
%\useoutertheme{split}
\title[Writer identification task]{Master Thesis proposal:\\Approaches for writer identification in \\
handwritten papyri}
\author{Lorenzo Sala}
\date{\today}
\institute{Stochastics and Data Science}
\begin{document}
\begin{frame}[plain]
    \maketitle
\end{frame}
\begin{frame}[c]
	\frametitle{Introduction}
	\begin{itemize}
		\item Papyri are an exception among ancient written artifacts in terms of preservation
		\item Most papyri went through the antiquity market where they were scattered around and split apart
		\item Identifying the writer over several fragments is beneficial for philology purposes
		\item Many papyri suffer from similar damage or corruption
		\item Non-harmonized approach in conservation
	\end{itemize}
\end{frame}
\begin{frame}
	\frametitle{Outline}
	\begin{itemize}
		\item Introduction on the problem of writer classification
		\item State of the art
		\item Two particular approaches to the problem
	\end{itemize}
\end{frame}
\begin{frame}
	\frametitle{Deep learning vs ``classic'' classification tasks}
	\begin{itemize}
		\item Since AlexNet in 2012, CNNs have been widely used in the image recognition field
		\item Nowadays newer techniques like Vision Transformers (e.g. Microsoft's Swim Transformer) offer potential improvements on CNNs
		\item DL techniques allow us:
		\begin{itemize}
			\item to avoid manual feature extraction
			\item to capture finer pattern
			\item to enjoy high flexibility (we can fine-tune models according to different scenarios)
		\end{itemize}
		\item The main drawback lies in the high computational cost and in the need for a significantly large labeled data set
		\item In this particular setting we have an extremely limited number datasets
	\end{itemize}
\end{frame}
\begin{frame}
	\frametitle{CNNs for writer identification}
	\begin{itemize}
		\item As a staple of computer vision and image classification, CNNs offer an extremely interesting option to learn visual features about handwriting
		\item As such, they are among the preferred methods for classification of handwriting
		\item Those models need a large amount of data needed for training (which is a problem in the case of manuscripts) and a relevant computational effort to run the training and the classification task itself
	\end{itemize}
\end{frame}
\begin{frame}
	\frametitle{A CNN applied to the classification of Greek handwriting (Christlein et al.)}
	\begin{figure}[h]
		\centering
		\includegraphics[width=\linewidth]{img/christlein}
		\label{fig:christlein}
	\end{figure}
\end{frame}
\begin{frame}
	\frametitle{State of the art in handwriting identification: DL approaches}
	\begin{itemize}
		\item Residual Swim Transformer: Vision Transformer (CNN which uses attention instead of convolution kernels) with residual connection in ResNet's style (Zhang et al.)
		\end{itemize}
		\begin{figure}[h]
			\centering
			\includegraphics[width=0.8\linewidth]{img/zhang}
			\label{fig:zhang}
		\end{figure}
		\end{frame}
		\begin{frame}
			\begin{itemize}
				\item FragNet64: features are extracted with a feature pyramid network and then each word is passed through the network to detect predictive fragments of words (He and Schomaker)
			\end{itemize}
			\begin{figure}
				\centering
				\includegraphics[width=0.7\linewidth]{img/fragnet}
				\label{fig:fragnet}
			\end{figure}
		\end{frame}
		\begin{frame}
			\begin{itemize}
		\item GR-RNN: Hybrid approach combining CNNs (for global patterns) with RNNs (for sequential patterns and gine grained information). This method achieved 95\% accuracy on the Firemaker dataset (He and Schomaker)
	\end{itemize}
	\begin{figure}
		\centering
		\includegraphics[width=0.9\linewidth]{img/grrnn}
		\label{fig:grrnn}
	\end{figure}
\end{frame}
\begin{frame}
	\frametitle{State of the art in handwriting identification: non DL approaches}
	\begin{itemize}
		\item Edge-based technique based on the probability density function of orientation and shape usage (Schomaker et al.)
	\end{itemize}
	\begin{figure}
		\centering
		\includegraphics[width=0.8\linewidth]{img/schomaker}
	\end{figure}
\end{frame}
\begin{frame}
	\begin{itemize}
		\item Texture based technique based on Basic Image Features (texture descriptors) and using them to create a ``style vector'' of each author against the average of all textures found in the document (Newell et al.)
	\end{itemize}
	\begin{figure}
		\centering
		\includegraphics[width=0.8\linewidth]{img/newell}
		\label{fig:newell}
	\end{figure}
\end{frame}
\begin{frame}
	\frametitle{State of the art in handwriting identification: non DL approaches}
	\begin{itemize}
		\item Directional method based on detecting junctions in the strokes and then looking at the distribution of the junction angles (He et al.)
	\end{itemize}
	\begin{figure}
		\centering
		\includegraphics[width=0.8\linewidth]{img/hejunction}
		\label{fig:hejunction}
	\end{figure}
\end{frame}
\begin{frame}
	\frametitle{A possible (DL) solution: Christlein's approach}
	\begin{itemize}
		\item Christlein et al. developed a method in 2017 for unsupervised feature learning for writer identification and writer retrieval
		\item In their approach, CNNs are not trained with a supervised approach (since no labeled training set is available)
		\item Instead, they train the CNN on graphical descriptors (SIFT) in an unsupervised way to extract robust features without determining the identity of the author
	\end{itemize}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\linewidth]{img/christlein2}
	\label{fig:christlein2}
\end{figure}
\end{frame}
\begin{frame}
	\frametitle{SIFT algorithm}
	\begin{itemize}
	\item The basic idea is to extract important points of an object represented in an image so that that object can be recognized in a different image
	\item The SIFT feature descriptor is invariant to uniform scaling, orientation, illumination and partially invariant to distortion
	\item The model is verified by a linear least squares estimation
	\end{itemize} 
	\begin{figure}[h]
		\centering
		\includegraphics[width=0.4\linewidth]{img/screenshot001}
		\caption{From Christlein's paper: example of (restricted) SIFT keypoints}
		\label{fig:screenshot001}
	\end{figure}
\end{frame}
\begin{frame}
	\frametitle{A possible (non DL) solution: Mamatsis approach}
	\begin{itemize}
		\item Mamatsis et al. developed a methond in 2023 to establish the authorship of two Greek documents discovered in Romania
		\item Instead of a DL approach, the authors use a geometric approach
		\item This bypasses the inherent problems of CNNs since it doesn't need extensive data for training
		\item It is leagues more computationally efficient
	\end{itemize}
\end{frame}
\begin{frame}
	\frametitle{Mamatsis' approach in writer retrieval}
	The authors propose the following workflow:
		\begin{enumerate}
			\item Bundles of ``optimally fit'' realizations of every alphabet symbol are created
		\item Among pixels of common curvature the mean of $x$ and $y$ coordinates is evaluated to obtain an average curved (``First-Version Representative'')
		\item The procedure is repeated in connection with all the First-Version Representatives to form an ``Ideal Representative'' of the form of the alphabet's symbol in the author's mind
		\item For each alphabet symbol separately the Ideal Representatives from two different documents are compared and then a statistical test is used against the hypothesis that the two documents are from the same hand.
	\end{enumerate}
\end{frame}
\begin{frame}
	\frametitle{Steps to find the ideal representative}
	\begin{itemize}
		\item \emph{Optimal matching}: examples of the same symbol are rotated, scaled and translated so that the similarity between them is maximised: this results in a bundle of optimally fit contours
		\item \emph{Suppressing discrepancies}: average curvatures are evaluated and the whole process (including matching) is repeated each time using a different example of a letter as starting prototype. In the end the curve with the least error is chosen
	\end{itemize}
	\begin{figure}[h]
		\centering
		\includegraphics[width=0.4\linewidth]{img/screenshot002}
		\caption{Bundle of optimally fit countours of $\varepsilon$ from Mamatsis' paper}
		\label{fig:screenshot002}
	\end{figure}
\end{frame}
\begin{frame}
	\frametitle{Example of ideal representatives}
	\begin{figure}
		\centering
		\includegraphics[width=0.4\linewidth]{img/mamatsis1}
		\label{fig:mamatsis1}
	\end{figure}
\end{frame}
\begin{frame}
	\frametitle{Conclusions}
	\begin{itemize}
		\item Different approaches bear different upsides and downsides
		\item Deep Learning approaches are more robust and accurate, but less feasible on a such a limited data pool
		\item Alternative approaches are more easy to realize but may not have the robustness of DL-based techniques
		\item The choose between the two roads is mainly dependent on the particular data available and on computing resources.
	\end{itemize}
\end{frame}
\end{document}
